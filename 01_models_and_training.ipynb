{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f7f024",
   "metadata": {},
   "source": [
    "This notebook is part of the paper: **Combining Deep Learning with Physics Based Features in Explosion-Earthquake Discrimination** published at Geophysical Research Letters. \n",
    "\n",
    "This notebook contains the two branch model built in the paper, and the training of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import timeit\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import layers, models, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './demo_data.npz'\n",
    "\n",
    "data = np.load(filename)\n",
    "\n",
    "# the waveform data\n",
    "X_waveform = data['X_waveform']\n",
    "# physics parameters, can be multiple\n",
    "X_param = data['X_param']\n",
    "# y label\n",
    "y = data['y']\n",
    "\n",
    "print(f\"The shapes: X_waveform: {X_waveform.shape}\\n\"\n",
    "      f\"The shapes: X_param: {X_param.shape}\\n\"\n",
    "      f\"The shapes: y: {y.shape}\\n\")\n",
    "\n",
    "# input to the two branch model\n",
    "X = [X_waveform, X_param]\n",
    "\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_branch_model(branch1_input_shape = (2000, 1, 3),\n",
    "                     branch2_input_shape = (1, ),\n",
    "                     root_filters = 64,\n",
    "                     pooling_size = (4, 1),\n",
    "                     kernel_size = (3, 1),\n",
    "                     n_layers = 2,\n",
    "                     clip_filters = None,\n",
    "                     activation = 'relu',\n",
    "                     cnn_dropout = 0.3,\n",
    "                     optimizer='adam',\n",
    "                     loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                     metrics=['acc']):\n",
    "    \n",
    "    # the proposed two-branch model\n",
    "    # Note: In the paper, we also can add another branch that takes in\n",
    "    # the spectrogram as input, it is very similar, so not repeat it here. \n",
    "    \n",
    "    # Branch 1 - deep learning branch\n",
    "    input_branch1 = Input(shape=branch1_input_shape)\n",
    "        \n",
    "    branch1 = layers.Conv2D(filters=root_filters,\n",
    "         kernel_size=kernel_size,\n",
    "         activation=activation, padding=\"same\")(input_branch1)\n",
    "    branch1 = layers.MaxPooling2D(pooling_size)(branch1)\n",
    "    n_kernels = root_filters\n",
    "    for i in range(n_layers):\n",
    "\n",
    "        if clip_filters:\n",
    "            if n_kernels > clip_filters:\n",
    "                n_kernels = clip_filters\n",
    "            else:\n",
    "                n_kernels *= 2\n",
    "        else:\n",
    "            n_kernels *= 2\n",
    "                \n",
    "        branch1 = layers.Conv2D(filters=n_kernels,\n",
    "         kernel_size=kernel_size,padding=\"same\",\n",
    "                         activation=activation)(branch1)\n",
    "        branch1 = layers.Dropout(cnn_dropout)(branch1)\n",
    "        branch1 = layers.MaxPooling2D(pooling_size)(branch1)\n",
    "\n",
    "    # convert image to vector \n",
    "    branch1 = layers.Flatten()(branch1)\n",
    "    \n",
    "    branch1 = layers.Dense(128, activation=activation)(branch1)\n",
    "    \n",
    "    # Branch 2, the physics parameter branch, can be multiple parameters\n",
    "    input_branch2 = layers.Input(shape=branch2_input_shape)\n",
    "    branch2 = layers.Dense(128, activation=tf.keras.activations.relu)(input_branch2)\n",
    "\n",
    "    # Concatenate the two branch features\n",
    "    concat = layers.Concatenate()([branch1, branch2])\n",
    "\n",
    "    # decision layer\n",
    "    concat = layers.Dropout(0.5)(concat)\n",
    "    concat = layers.Dense(100, activation=activation)(concat)\n",
    "    output = layers.Dense(2, activation='softmax')(concat)\n",
    "\n",
    "    model = models.Model(inputs=[input_branch1, input_branch2], outputs=[output])\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cedb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '1_0'\n",
    "output_path = f'./trained_model/combined_CNN_ANN_model_ver{version}'\n",
    "filepath = f'{output_path}/my_best_model.hdf5'\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max'),\n",
    "             EarlyStopping(monitor='val_acc',\n",
    "                           mode='max',\n",
    "                           patience=30),\n",
    "             TensorBoard(log_dir=f\"{output_path}/logs\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "# settings\n",
    "tf.keras.backend.clear_session()\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# run the training and testing using multiple GPUs\n",
    "with mirrored_strategy.scope():\n",
    "\n",
    "    model = two_branch_model() \n",
    "\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        class_weight = 'balanced',classes=np.unique(y),y=y)\n",
    "    class_weights = {0:class_weights[0], 1:class_weights[1]}\n",
    "    print(f\"The class weights are: {class_weights}\")\n",
    "\n",
    "    # record time and start training\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "    history = model.fit(X, y, epochs=2, \n",
    "                    validation_split=0.2,\n",
    "                    batch_size=256,\n",
    "                    shuffle=True,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights\n",
    "                                )\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    # finish training\n",
    "\n",
    "    # save the model structure as figure\n",
    "    tf.keras.utils.plot_model(model, to_file=f'{output_path}/model.png', show_shapes=True)\n",
    "\n",
    "    # save the training curve\n",
    "    plt.plot(history.history['acc'], label='training acc')\n",
    "    plt.plot(history.history['val_acc'], label='validation acc')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(f'{output_path}/training_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "    results = {}\n",
    "    results['history_curve'] = history.history\n",
    "    results['training_time_s'] = elapsed\n",
    "\n",
    "    json.dump(results, open(f'{output_path}/history.json', 'w'))\n",
    "\n",
    "    # load the trained model\n",
    "    model = tf.keras.models.load_model(f'{output_path}/my_best_model.hdf5')\n",
    "\n",
    "    print('Done saving the results!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a2e66",
   "metadata": {},
   "source": [
    "## Models for comparison purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ann(input_shape = (1, ),\n",
    "                root_neurons = 16,\n",
    "                dropout = 0.3,\n",
    "                n_layers = 4,\n",
    "                clip_neurons = None,\n",
    "                activation='relu',\n",
    "                output_class = 2,\n",
    "                output_activation='softmax'\n",
    "                ):\n",
    "    # physics parameter branch for comparison purpose. \n",
    "    \n",
    "    # build cnn layers\n",
    "    inputs = Input(shape=input_shape)\n",
    "    y = layers.Dense(root_neurons, activation=activation)(inputs)\n",
    "    y = layers.Dropout(dropout)(y)\n",
    "    \n",
    "    n_neuron = root_neurons\n",
    "    for i in range(n_layers):\n",
    "\n",
    "        if clip_neurons:\n",
    "            if n_neuron > clip_neurons:\n",
    "                n_neuron = clip_neurons\n",
    "            else:\n",
    "                n_neuron *= 2\n",
    "        else:\n",
    "            n_neuron *= 2\n",
    "                \n",
    "        y = layers.Dense(n_neuron, activation=activation)(y)\n",
    "        y = layers.Dropout(dropout)(y)\n",
    "\n",
    "    outputs = layers.Dense(output_class, activation=output_activation)(y)\n",
    "     # model building by supplying inputs/outputs\n",
    "    baseline_model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    baseline_model.summary()\n",
    "    baseline_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['acc'])\n",
    "    return baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn(input_shape = (2000, 1, 3),\n",
    "                kernel_size = (3, 1),\n",
    "                pooling_size = (2, 1),\n",
    "                root_filters = 16,\n",
    "                clip_filters = None,\n",
    "                dense_dropout = 0.3,\n",
    "                cnn_dropout = 0.1,\n",
    "                n_layers = 4,\n",
    "                activation='relu',\n",
    "                output_class = 2,\n",
    "                output_activation='softmax'\n",
    "                ):\n",
    "    \n",
    "    # deep learning branch model for comparison purpose. \n",
    "    \n",
    "    # build cnn layers\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    y = layers.Conv2D(filters=root_filters,\n",
    "         kernel_size=kernel_size,\n",
    "         activation=activation, padding=\"same\")(inputs)\n",
    "    y = layers.MaxPooling2D(pooling_size)(y)\n",
    "    n_kernels = root_filters\n",
    "    for i in range(n_layers):\n",
    "\n",
    "        if clip_filters:\n",
    "            if n_kernels > clip_filters:\n",
    "                n_kernels = clip_filters\n",
    "            else:\n",
    "                n_kernels *= 2\n",
    "        else:\n",
    "            n_kernels *= 2\n",
    "                \n",
    "        y = layers.Conv2D(filters=n_kernels,\n",
    "         kernel_size=kernel_size,padding=\"same\",\n",
    "                         activation=activation)(y)\n",
    "        y = layers.Dropout(cnn_dropout)(y)\n",
    "        y = layers.MaxPooling2D(pooling_size)(y)\n",
    "\n",
    "    # convert image to vector \n",
    "    y = layers.Flatten()(y)\n",
    "    # dropout regularization\n",
    "    y = layers.Dropout(dense_dropout)(y)\n",
    "    y = layers.Dense(100, activation=activation)(y)\n",
    "    outputs = layers.Dense(output_class, activation=output_activation)(y)\n",
    "     # model building by supplying inputs/outputs\n",
    "    baseline_model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    baseline_model.summary()\n",
    "    baseline_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['acc'])\n",
    "    return baseline_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
